1. exe folder contains Model deployment exe files that can be run directly, including the corresponding Model (onnx model), csv (sample test dataset), report (Inference results report), and onnxruntime folder
2. The source code of Model deployment software is stored in src, and the software is written in QT and C++ (the model path needs to be configured when modifying the source code)
If you find that it cannot start normally, please check whether the dll file in the exe exists (downloaded in Microsoft Visual Studio)
The onnxruntime related folder is the onnxruntime official runtime library, which is responsible for onnx model inference. Users must ensure that the official library is imported when using it
3. Users can import custom network models, and the program automatically selects the custom models after importing.
4. Users can add new datasets by importing a configuration file, the first row of the profile is the dataset name, the second row is the number of classifications, and the third row is the label of each category (separated by , ). After the configuration file is imported, the new dataset configuration information is added to the drop-down box.
5. After the user clicks the "Import Data and inference" button, the dataset selected in the current drop-down box is opened, the software can perform batch prediction and report generation, and the report is saved in the "report" folder.